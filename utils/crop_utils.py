import pyautogui
import matplotlib.pyplot as plt
from matplotlib.backend_bases import MouseEvent
from matplotlib.widgets import RectangleSelector
import numpy as np
import cv2
import pyautogui
import pims
import trackpy as tp
import ipywidgets as widgets
from IPython.display import display
from utils.tp_plots import annotate  # module of modified trackpy plotting functions


class ScreenshotCoords:
    """Class for storing coordinates to be used in pyautogui.screenshot(), AKA
    (left, top, width, height)

    Coordinates obtained using matplotlib.widgets.RectangleSelector and set using
    the associated setter methods in ScreenshotCoords"""

    def __init__(self):
        self.left = 0
        self.top = 0
        self.width = 0
        self.height = 0

    def set_left(self, left):
        self.left = left

    def set_top(self, top):
        self.top = top

    def set_width(self, width):
        self.width = width

    def set_height(self, height):
        self.height = height


def update_crop_selection(
    eclick:MouseEvent,
    erelease:MouseEvent,
    coords: ScreenshotCoords
):
    """Callback function for RectangleSelector; allows you to select a section
    of an initial screenshot and updates screen coordinates to be used by
    pyautogui.screenshot()

    ____________________

    PARAMETERS:
    eclick: MouseEvent class defining where a rectangle selection started\n
    erelease: MouseEvent class defining where a rectangle selection ended\n
    coords: ScreenshotCoords object to hold coordinates from eclick and erelease
    
    ____________________

    RETURNS:

    Nothing"""

    # coordinates for pyautogui.screenshot()
    x1, y1 = eclick.xdata, eclick.ydata
    x2, y2 = erelease.xdata, erelease.ydata

    # store coordinates in global vars
    coords.set_left(min(x1, x2))
    coords.set_top(min(y1, y2))
    coords.set_width(np.abs(x1 - x2))
    coords.set_height(np.abs(y1 - y2))


def track_screenshots(coords:ScreenshotCoords, params:dict, dfs:list):
    """Continuously screenshots a location on screen, applies trackpy.locate()
    to locate cells, and displays the annotated image using cv2.imshow()

    Screen location specified by a ScreenshotCoords object (coords). Parameters
    to trackpy.locate() are stored in a dictionary (params).
    
    ____________________

    PARAMETERS:
    coords: ScreenshotCoords object to hold coordinates from eclick and erelease\n
    params: Dictionary containing trackpy.locate parameters
    
    ____________________

    RETURNS:

    Nothing"""

    tp.quiet()

    while True:

        # take screenshot, convert to numpy array, grayscale, and convert to PIMS object
        img = pyautogui.screenshot(region = (coords.left, coords.top, coords.width, coords.height))
        frame = np.array(img)
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        pim_gray = pims.frame.Frame(gray)   # turn grayscale into PIMS Frame object

        # get feature location DataFrame
        f = tp.locate(
            pim_gray,
            diameter=params["diameter"],
            minmass=params["minmass"],
            maxsize=params["maxsize"],
            threshold=params["threshold"],
            noise_size=params["noise_size"],
            topn=params["topn"],
            separation=params["separation"],
            smoothing_size=params["smoothing_size"],
            invert=True,
            engine="numba"
        )

        if dfs != None:
            dfs.append(f)

        # # First argument specifies how many pixels an object is allowed to move per frame
        # # Second argument specifies how many frames an object is allowed to be unseen before being removed
        # t = tp.link_df(f, 10, memory=10)

        # # Only keep trajectories that are present for X amount of frames, where X is the argument
        # t1 = tp.filter_stubs(t, 20)

        # Get plt figure generated by trackpy's annotate; requires pd.DataFrame and PIMS object
        fig = annotate(f, pim_gray).figure
        # fig = annotate(t1, pim_gray).figure

        # remove margins and axes from figure to only get annotated figure image
        ax = fig.gca()
        ax.axis('off')
        fig.tight_layout(pad=0)
        ax.margins(0)

        # Draw image onto plt canvas and convert into a numpy ndarray
        fig.canvas.draw()
        image_from_plot = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)
        image_from_plot = image_from_plot.reshape(fig.canvas.get_width_height()[::-1] + (3,))
        cv2.imshow('image', image_from_plot) # show annotated image
        fig.clear(True) # clear canvas for next preprocessed image
            

        # press q to quit program
        if cv2.waitKey(1) == ord("q"):
            break


def clear_windows():
    """Closes all cv2 and plt windows"""

    cv2.destroyAllWindows()
    plt.close('all')